A diferencia de los dos algoritmos previos, en Thompson Sampling no existe un parámetro que se pueda explorar. Sin embargo, como ya se ha visto en el capítulo \ref{CAP:ALGORITMOS}, se puede modificar la distribución que sigue la recompensa asociada a cada item variando los parámetros $\alpha$ y $\beta$ de la distribución Beta, donde:
$$\alpha = 1+ n\acute{u}mero \ de \ aciertos$$
$$\beta = 1+ n\acute{u}mero \ de \ fallos$$

Por tanto, una exploración de los parámetros $\alpha$ y $\beta$ del algoritmo de Thompson Sampling, equivale a la exploración optimista y pesimista realizada para los dos algoritmos anteriores.

Los resultados correspondientes a este experimento se muestran un mapa de color en la figura \ref{FIG:TSOpCm100k}

\begin{figure}[Mapa de color de Thompson Sampling]{FIG:TSOpCm100k}{Resultados de la exploración optimista/pesimista}
        \image{7cm}{}{cm100k/MapaThompson}
\end{figure}

El resultado es muy similar al obtenido en \ref{FIG:UcbOpCm100k}. En esta ocasión el máximo se alcanza para valores de $\alpha=1$ y $\beta$ entre 7 y 9 y el mínimo en $\alpha=9, \ \beta=2$. Se observa un máximo local en la región de recall bajo (color rojo) en $\alpha=4, \ \beta=5$
